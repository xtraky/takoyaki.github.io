- [A Cost Analysis of Generative Language Models and Influence Operations](https://arxiv.org/abs/2308.03740v1)
  - LLMがプロパガンダに悪用されることを想定し、コスト観点で影響を検討
    - ①LLMはプロパガンダコンテンツの生成コストをどれだけ削減するか(2,3章)
      - 低信頼な出力のモデルでもコスト削減効果あり。高信頼モデルのコスト削減効果は最大70%
      - ＃信頼性は「使える出力が得られる確率」で表している。LLMガチャでどれだけスカを引くことになるか
    - ②LLMのAPIを監視することはどれほど抑止効果を持つか(4,5章)
      - オープンソースモデルが利用できる場合、API監視による抑止効果は限定的
    - ③オープンソースモデルを使う場合があるか(6章)：
      - オープンソースモデルを使う場合、ファインチューニングに要する固定費が高い。メリットが出るのは以下のケース
        - 大量に出力する　＃入力もか
        - ＃ファインチューニング＝コストをかけて信頼性を上げる操作
  - ＃以下、その他の観点
    - ＃コストと信頼性(スカ率)のトレードオフなので、顧客と直接相対するケースではスカを極限まで減らすモチベーションがある
    - ＃スループットの議論がない。既存API利用ではスループット要件を満たせないケースが考えられる

- [OpenAIのレートリミット](https://platform.openai.com/account/rate-limits)
  - gpt-3.5-turbo: 90000 tpm
  - gpt-4: 10000 tpm

- [公開シンポジウム「生成AIの課題と今後」](https://www.youtube.com/watch?v=uw8_DEm3exg)
  - 公開シンポジウム「先生AIの課題と今後」が開催され、AIの現状と課題について議論が行われた。大規模言語モデルの開発や日本語の言語モデルの進化、AIの社会への影響などが主な議論のテーマだった。また、AIの活用と懸念に対する対策についてLINEの井尻善久氏が講演を行い、AIの進展によるイノベーションの可能性や法的、**経済的課題**、倫理的課題などについて語った。さらに、AIの生成物が他社の著作権を侵害する可能性や個人情報の利用についての問題、AIの利用に関する倫理的、社会的な問題も考慮し、AIガバナンスの議論が必要であると述べられた。また、AIの学習モデルやその進化についての議論が行われ、**カリキュラムラーニング**のような手法で効率的に学習を進めることが可能であると述べられた。しかし、現在の**トランスフォーマーモデルの限界**も認識されており、新たなモデルの提案が必要とされている。さらに、AIと人間の共生についての議論や、AIの浸透による仕事の失失、AIと法の関係、著作権法の問題などについても触れられた。これらの議論を通じて、AIの開発や適用には多様な視点からの理解と対策が必要であるとの意見が示された。
    - **経済的課題**：既存エコシステムの破壊、利益分配、収益性
    - **カリキュラムラーニング**：
      - 論理的推論はできるようになるのか？という文脈
      - タスク分解して簡単なものから教えたら複雑なこともできるのでは、という主旨
    - **トランスフォーマーモデルの限界**：
      - こちらも論理的推論の文脈。下記のいずれかをきっかけにブレークスルーが起こるのでは、という主旨
        - 新たなモデル構造が提案される
        - パラメータサイズが現状の数百倍になったときに新たな現象が起きる
